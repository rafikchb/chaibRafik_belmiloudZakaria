{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comfortable-advertising",
   "metadata": {},
   "source": [
    "### On créer un modèle depuis le fichier de la  pahse2 pour pouvoir associer  les 1 est 0 de la phase3 avec les valeur anomaly ou normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "included-contest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleur parametre pour notre knn sont :  {'metric': 'manhattan', 'n_neighbors': 3}\n",
      "score   0.938\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dfPh2= pd.read_csv(\"files/Phase2.csv\")\n",
    "dfPh2 = dfPh2.fillna(dfPh2.median())\n",
    "dfPh2= dfPh2.drop_duplicates(keep='first').reset_index()\n",
    "\n",
    "txtDataColumn = ['protocol_type','service','flag']\n",
    "dfPh2 = dfPh2.drop(txtDataColumn, axis= 1)\n",
    "\n",
    "x = dfPh2.drop(\"class\",axis = 1) #getting the features of the data in a matrix\n",
    "y = dfPh2[\"class\"]  # getting the label of the data in a  vector\n",
    "X_train, X_test , y_train , y_test = train_test_split(x , y, test_size=0.3,stratify=y )\n",
    "\n",
    "param_grid= {'n_neighbors' : [3,5,7,9,11,13,15,17], \n",
    "'metric' : ['manhattan', 'euclidean']\n",
    "}\n",
    "grid = GridSearchCV(KNeighborsClassifier(),param_grid, cv = 5) #initiamlisation du grid estimator \n",
    "grid.fit(X_train, y_train)# entrainement du grid (kfold)\n",
    "print('les meilleur parametre pour notre knn sont : ', grid.best_params_)\n",
    "modelKnn = grid.best_estimator_\n",
    "print('score  ',round(modelKnn.score(X_test, y_test),3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blank-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 'anomaly'], [0.0, 'anomaly'], [0.0, 'normal'], [0.0, 'anomaly'], [0.0, 'anomaly'], [0.0, 'normal'], [0.0, 'normal'], [0.0, 'normal'], [0.0, 'normal'], [0.0, 'normal'], [0.0, 'anomaly'], [0.0, 'normal'], [0.0, 'anomaly'], [0.0, 'anomaly'], [0.0, 'normal'], [0.0, 'normal'], [0.0, 'normal'], [0.0, 'normal'], [0.0, 'normal'], [0.0, 'anomaly']]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"files/fromPhase3.csv\")\n",
    "listemoinData = []\n",
    "for i in range(20):\n",
    "    temoindata = df.iloc[i]\n",
    "    temoindata= temoindata.to_frame().transpose()\n",
    "    classReal = modelKnn.predict(temoindata.drop(\"class\",axis = 1)) \n",
    "    listemoinData.append([temoindata.iloc[0]['class'],classReal[0]])\n",
    "print(listemoinData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-interaction",
   "metadata": {},
   "source": [
    "D'après le résultat obtenue dans la dernier cellule en peut en conclure que , 0 = anomaly , 1 = normal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-ethiopia",
   "metadata": {},
   "source": [
    "### on remplace nos donner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deadly-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].replace(to_replace =[0,1], value = ['anomaly','normal'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-manor",
   "metadata": {},
   "source": [
    "### faire un modéle knn avec les donner des deux phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stainless-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"files/Phase2.csv\")\n",
    "df3 = df1.append(df, ignore_index = True) \n",
    "####\n",
    "df3 = df3.fillna(df3.median())\n",
    "df3= df3.drop_duplicates(keep='first').reset_index()\n",
    "txtDataColumn = ['protocol_type','service','flag']\n",
    "df3 = pd.get_dummies(df3,columns=txtDataColumn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "straight-glossary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleur parametre pour notre knn sont :  {'metric': 'manhattan', 'n_neighbors': 3}\n",
      "score de notre modelle :  0.968\n"
     ]
    }
   ],
   "source": [
    "x = df3.drop(\"class\",axis = 1) #getting the features of the data in a matrix \n",
    "y = df3[\"class\"] #getting the labes of the data in a vector \n",
    "X_train, X_test , y_train , y_test = train_test_split(x , y, test_size=0.3,stratify=y ) \n",
    "\n",
    "param_grid= {'n_neighbors' : [3,5,7,9,11,13,15,17], \n",
    "'metric' : ['manhattan', 'euclidean']\n",
    "}\n",
    "grid = GridSearchCV(KNeighborsClassifier(),param_grid, cv = 5) #initiamlisation du grid estimator \n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('les meilleur parametre pour notre knn sont : ', grid.best_params_)\n",
    "print('score de notre modelle : ' , round(grid.best_score_,3))\n",
    "\n",
    "bestEstimator = grid.best_estimator_#sauvgarde du modelle \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-nutrition",
   "metadata": {},
   "source": [
    "### on obtient ainsi un classificateur robuste avec , avec un score de 0.968\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
