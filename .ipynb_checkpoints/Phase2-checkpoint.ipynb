{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "clinical-creek",
   "metadata": {},
   "source": [
    "# Question 2.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "renewable-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"files/Phase2.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-scenario",
   "metadata": {},
   "source": [
    "### Description  des donner  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pregnant-challenge",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25192 entries, 0 to 25191\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     25192 non-null  int64  \n",
      " 1   protocol_type                25192 non-null  object \n",
      " 2   service                      25192 non-null  object \n",
      " 3   flag                         25192 non-null  object \n",
      " 4   src_bytes                    25192 non-null  int64  \n",
      " 5   dst_bytes                    25192 non-null  int64  \n",
      " 6   land                         25192 non-null  int64  \n",
      " 7   wrong_fragment               25192 non-null  int64  \n",
      " 8   urgent                       25192 non-null  int64  \n",
      " 9   hot                          25192 non-null  int64  \n",
      " 10  num_failed_logins            25192 non-null  int64  \n",
      " 11  logged_in                    25192 non-null  int64  \n",
      " 12  num_compromised              25192 non-null  int64  \n",
      " 13  root_shell                   25192 non-null  int64  \n",
      " 14  su_attempted                 25192 non-null  int64  \n",
      " 15  num_root                     25192 non-null  int64  \n",
      " 16  num_file_creations           25192 non-null  int64  \n",
      " 17  num_shells                   25192 non-null  int64  \n",
      " 18  num_access_files             25192 non-null  int64  \n",
      " 19  num_outbound_cmds            25192 non-null  int64  \n",
      " 20  is_host_login                25192 non-null  int64  \n",
      " 21  is_guest_login               25192 non-null  int64  \n",
      " 22  count                        25192 non-null  int64  \n",
      " 23  srv_count                    25192 non-null  int64  \n",
      " 24  serror_rate                  25192 non-null  float64\n",
      " 25  srv_serror_rate              25192 non-null  float64\n",
      " 26  rerror_rate                  25192 non-null  float64\n",
      " 27  srv_rerror_rate              25192 non-null  float64\n",
      " 28  same_srv_rate                25192 non-null  float64\n",
      " 29  diff_srv_rate                25192 non-null  float64\n",
      " 30  srv_diff_host_rate           25192 non-null  float64\n",
      " 31  dst_host_count               25192 non-null  int64  \n",
      " 32  dst_host_srv_count           25192 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       25192 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       25192 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  25192 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  25192 non-null  float64\n",
      " 37  dst_host_serror_rate         25192 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     25192 non-null  float64\n",
      " 39  dst_host_rerror_rate         25192 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     25192 non-null  float64\n",
      " 41  class                        25192 non-null  object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cutting-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           duration     src_bytes     dst_bytes          land  wrong_fragment  \\\n",
      "count  25192.000000  2.519200e+04  2.519200e+04  25192.000000    25192.000000   \n",
      "mean     305.054104  2.433063e+04  3.491847e+03      0.000079        0.023738   \n",
      "std     2686.555640  2.410805e+06  8.883072e+04      0.008910        0.260221   \n",
      "min        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
      "25%        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
      "50%        0.000000  4.400000e+01  0.000000e+00      0.000000        0.000000   \n",
      "75%        0.000000  2.790000e+02  5.302500e+02      0.000000        0.000000   \n",
      "max    42862.000000  3.817091e+08  5.151385e+06      1.000000        3.000000   \n",
      "\n",
      "            urgent           hot  num_failed_logins     logged_in  \\\n",
      "count  25192.00000  25192.000000       25192.000000  25192.000000   \n",
      "mean       0.00004      0.198039           0.001191      0.394768   \n",
      "std        0.00630      2.154202           0.045418      0.488811   \n",
      "min        0.00000      0.000000           0.000000      0.000000   \n",
      "25%        0.00000      0.000000           0.000000      0.000000   \n",
      "50%        0.00000      0.000000           0.000000      0.000000   \n",
      "75%        0.00000      0.000000           0.000000      1.000000   \n",
      "max        1.00000     77.000000           4.000000      1.000000   \n",
      "\n",
      "       num_compromised  ...  dst_host_count  dst_host_srv_count  \\\n",
      "count     25192.000000  ...    25192.000000        25192.000000   \n",
      "mean          0.227850  ...      182.532074          115.063036   \n",
      "std          10.417352  ...       98.993895          110.646850   \n",
      "min           0.000000  ...        0.000000            0.000000   \n",
      "25%           0.000000  ...       84.000000           10.000000   \n",
      "50%           0.000000  ...      255.000000           61.000000   \n",
      "75%           0.000000  ...      255.000000          255.000000   \n",
      "max         884.000000  ...      255.000000          255.000000   \n",
      "\n",
      "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "count            25192.000000            25192.000000   \n",
      "mean                 0.519791                0.082539   \n",
      "std                  0.448944                0.187191   \n",
      "min                  0.000000                0.000000   \n",
      "25%                  0.050000                0.000000   \n",
      "50%                  0.510000                0.030000   \n",
      "75%                  1.000000                0.070000   \n",
      "max                  1.000000                1.000000   \n",
      "\n",
      "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "count                 25192.000000                 25192.000000   \n",
      "mean                      0.147453                     0.031844   \n",
      "std                       0.308367                     0.110575   \n",
      "min                       0.000000                     0.000000   \n",
      "25%                       0.000000                     0.000000   \n",
      "50%                       0.000000                     0.000000   \n",
      "75%                       0.060000                     0.020000   \n",
      "max                       1.000000                     1.000000   \n",
      "\n",
      "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "count          25192.000000              25192.000000          25192.000000   \n",
      "mean               0.285800                  0.279846              0.117800   \n",
      "std                0.445316                  0.446075              0.305869   \n",
      "min                0.000000                  0.000000              0.000000   \n",
      "25%                0.000000                  0.000000              0.000000   \n",
      "50%                0.000000                  0.000000              0.000000   \n",
      "75%                1.000000                  1.000000              0.000000   \n",
      "max                1.000000                  1.000000              1.000000   \n",
      "\n",
      "       dst_host_srv_rerror_rate  \n",
      "count              25192.000000  \n",
      "mean                   0.118769  \n",
      "std                    0.317333  \n",
      "min                    0.000000  \n",
      "25%                    0.000000  \n",
      "50%                    0.000000  \n",
      "75%                    0.000000  \n",
      "max                    1.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-personality",
   "metadata": {},
   "source": [
    "### Gestion des valeur null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ignored-window",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " affichage des valeur null par column :  duration                       0\n",
      "protocol_type                  0\n",
      "service                        0\n",
      "flag                           0\n",
      "src_bytes                      0\n",
      "dst_bytes                      0\n",
      "land                           0\n",
      "wrong_fragment                 0\n",
      "urgent                         0\n",
      "hot                            0\n",
      "num_failed_logins              0\n",
      "logged_in                      0\n",
      "num_compromised                0\n",
      "root_shell                     0\n",
      "su_attempted                   0\n",
      "num_root                       0\n",
      "num_file_creations             0\n",
      "num_shells                     0\n",
      "num_access_files               0\n",
      "num_outbound_cmds              0\n",
      "is_host_login                  0\n",
      "is_guest_login                 0\n",
      "count                          0\n",
      "srv_count                      0\n",
      "serror_rate                    0\n",
      "srv_serror_rate                0\n",
      "rerror_rate                    0\n",
      "srv_rerror_rate                0\n",
      "same_srv_rate                  0\n",
      "diff_srv_rate                  0\n",
      "srv_diff_host_rate             0\n",
      "dst_host_count                 0\n",
      "dst_host_srv_count             0\n",
      "dst_host_same_srv_rate         0\n",
      "dst_host_diff_srv_rate         0\n",
      "dst_host_same_src_port_rate    0\n",
      "dst_host_srv_diff_host_rate    0\n",
      "dst_host_serror_rate           0\n",
      "dst_host_srv_serror_rate       0\n",
      "dst_host_rerror_rate           0\n",
      "dst_host_srv_rerror_rate       0\n",
      "class                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(' affichage des valeur null par column : ', df.isnull().sum()) #afficher lles valeur null par column \n",
    "df = df.fillna(df.median())# remplire les valeur nulle par la valeur median , nous navont pas de valuer null pour notre cas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-brighton",
   "metadata": {},
   "source": [
    "### Gestion des valeurs redondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "forbidden-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop_duplicates(keep='first').reset_index()# dellting of all the rows that are duplicate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-private",
   "metadata": {},
   "source": [
    "### Transformation des donner \n",
    "utilisation dune codification one hoting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "known-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtDataColumn = ['protocol_type','service','flag']\n",
    "df = pd.get_dummies(df,columns=txtDataColumn) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-stroke",
   "metadata": {},
   "source": [
    "### les info les plus pertinente a garder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "right-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourcentage des noraml : 53.386 %\n",
      "pourcentage des anomaly : 46.614 %\n"
     ]
    }
   ],
   "source": [
    "t = df[\"class\"].value_counts()\n",
    "print(\"pourcentage des noraml :\",round( t[\"normal\"]*100/df[\"class\"].count(), 3),\"%\")\n",
    "print(\"pourcentage des anomaly :\",round(t[\"anomaly\"]*100/df[\"class\"].count(), 3),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-genre",
   "metadata": {},
   "source": [
    "### Réponse à la deuxième partie de la question : \n",
    "#### les changement ajouter au donner sont l’ajout de nouvelle donner de la class anomaly, ce qui a  provoquer l’augmentation du nombre de donner dans notre data-set ainsi que la création d’un équilibre entre le nombre de donner des deux class. avec un pourcentage de 53.386 % pour les normal, et 46.614 % pour les anomaly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-galaxy",
   "metadata": {},
   "source": [
    "# Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lesbian-probe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les meilleur parametre pour notre knn sont :  {'metric': 'manhattan', 'n_neighbors': 3}\n",
      "\n",
      "pour la class ANOMALY :\n",
      "precision =  0.919672131147541\n",
      "recall =  0.9554357082032359\n",
      "f1_score = \n",
      "\n",
      " 0.9372128637059725\n",
      "pour la class NORMAL :\n",
      "precision= 0.9597229348383787\n",
      "recall= 0.9271375464684015\n",
      "f1_score  0.9431488718013362\n",
      "\n",
      "le f1 score moyen est de  0.9401808677536543\n",
      ".score  0.9403281291346918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "x = df.drop(\"class\",axis = 1) #getting the features of the data in a matrix \n",
    "y = df[\"class\"] #getting the labes of the data in a vector \n",
    "X_train, X_test , y_train , y_test = train_test_split(x , y, test_size=0.3,stratify=y ) \n",
    "\n",
    "param_grid= {'n_neighbors' : [3,5,7,9,11,13,15,17], \n",
    "'metric' : ['manhattan', 'euclidean']\n",
    "}\n",
    "grid = GridSearchCV(KNeighborsClassifier(),param_grid, cv = 5) #initiamlisation du grid estimator \n",
    "grid.fit(X_train, y_train)# entrainement du grid (kfold)\n",
    "print('les meilleur parametre pour notre knn sont : ', grid.best_params_)\n",
    "bestEstimator = grid.best_estimator_#on garde le modelle avec les mielleur parametre \n",
    "y_pred=bestEstimator.predict(X_test) \n",
    "\n",
    "print('\\npour la class ANOMALY :')\n",
    "af1score = f1_score(y_test, y_pred, pos_label = 'anomaly')\n",
    "print('precision = ',round(precision_score(y_test,y_pred, pos_label = 'anomaly'),3))\n",
    "print('recall = ',round(recall_score(y_test,y_pred,pos_label = 'anomaly'),3))\n",
    "print('f1_score = ',round(af1score,3))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print('pour la class NORMAL :')\n",
    "nf1score = f1_score(y_test, y_pred, pos_label = 'normal')\n",
    "print('precision=',round(precision_score(y_test,y_pred, pos_label = 'normal'),3))\n",
    "print('recall=',round(recall_score(y_test,y_pred,pos_label = 'normal'),3))\n",
    "print('f1_score ',round(nf1score ,3))\n",
    "\n",
    "mean_f1 = ((af1score + nf1score)/2)\n",
    "print('\\nle f1-score moyen est de ',round(mean_f1,3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-rwanda",
   "metadata": {},
   "source": [
    "### Réponse de la dernière question :\n",
    "#### Oui ce changement a un impact sur la performance du classificateur, on remarque que le f1-score du modèle de la phase 2 est plus bas que celui de la phase 1 ,  justification  le score obtenue de puis la phase 1 est le score pour la phase 2 qui se trouve juste au-dessus de cette cellule est qui est de  0.940\n",
    "#### Remarque : il faut savoir que le score obtenue dans la phase 1 est un résultat biaiser à cause du  data-set qui n'ait pas homogène pour les deux class avec , 98,9 normal %, 1.1 anomaly %, le score de 1 ne reflète pas la performance de notre model sur des donner que il n’a jamais vu .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-solid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
